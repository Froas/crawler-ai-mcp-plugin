import requests
from bs4 import BeautifulSoup
import json
import time
import re


def jpx_two_step_request():
    """
    –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—è (–æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞)
    """
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive'
    })

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã form-data —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ Insomnia
    form_data = {
        'dspSsuPd': '500',
        'szkbuChkbxMapOut': '011>Prime<012>Standard<013>Growth<008>TOKYO',
        'ListShow': 'ListShow',
        'sniMtGmnId': '',
        'dspSsuPdMapOut': '10>10<50>50<100>100<200>200<',
        'mgrMiTxtBx': '',
        'eqMgrCd': '',
        'szkbuChkbx': '011'
    }

    try:
        # –ü–ï–†–í–´–ô –ó–ê–ü–†–û–° - –æ—Ç–∫—Ä—ã—Ç–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞
        print("–ó–ê–ü–†–û–° 1: –û—Ç–∫—Ä—ã—Ç–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞...")
        url = "https://www2.jpx.co.jp/tseHpFront/JJK020010Action.do;jsessionid=00B11CD09F0EE52A255F89C8F3D3F8A21"

        response1 = session.post(url, data=form_data)
        response1.raise_for_status()

        print(f"–ó–∞–ø—Ä–æ—Å 1 - –°—Ç–∞—Ç—É—Å: {response1.status_code}")

        # –í–¢–û–†–û–ô –ó–ê–ü–†–û–° - –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n–ó–ê–ü–†–û–° 2: –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        response2 = session.post(url, data=form_data)
        response2.raise_for_status()

        print(f"–ó–∞–ø—Ä–æ—Å 2 - –°—Ç–∞—Ç—É—Å: {response2.status_code}")
        print(f"–ó–∞–ø—Ä–æ—Å 2 - –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response2.content)} –±–∞–π—Ç")

        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        soup = BeautifulSoup(response2.content, 'html.parser')
        enhanced_data = parse_companies_from_soup(soup)

        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(enhanced_data)}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'success': True,
            'method': 'two_step_request',
            'companies_count': len(enhanced_data),
            'companies': enhanced_data
        }

        return result

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return {'success': False, 'error': str(e)}


def jpx_with_pagination(max_pages=None, delay=1, search_params=None):
    """
    –í–µ—Ä—Å–∏—è —Å pagination –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–±–æ—á–µ–≥–æ –∫–æ–¥–∞
    """
    if search_params is None:
        search_params = {
            'dspSsuPd': '500',
            'szkbuChkbxMapOut': '011>Prime<012>Standard<013>Growth<008>TOKYO',
            'ListShow': 'ListShow',
            'sniMtGmnId': '',
            'dspSsuPdMapOut': '10>10<50>50<100>100<200>200<',
            'mgrMiTxtBx': '',
            'eqMgrCd': '',
            'szkbuChkbx': '011'
        }

    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive'
    })

    all_companies = []
    all_statistics = {'segments': {}, 'industries': {}}
    current_page = 1
    total_items = None
    total_pages = None

    try:
        while True:
            print(f"\n{'=' * 60}")
            print(f"üìÑ –°–¢–†–ê–ù–ò–¶–ê {current_page}")
            if total_pages:
                print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {current_page}/{total_pages}")
            if total_items:
                print(f"üéØ –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {total_items}")
            print(f"{'=' * 60}")

            # –ì–æ—Ç–æ–≤–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            form_data = search_params.copy()

            # –ü–ï–†–í–´–ô –ó–ê–ü–†–û–°
            print(f"–ó–ê–ü–†–û–° 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}...")
            url = "https://www2.jpx.co.jp/tseHpFront/JJK020010Action.do;jsessionid=00B11CD09F0EE52A255F89C8F3D3F8A21"

            response1 = session.post(url, data=form_data)
            response1.raise_for_status()

            # –í–¢–û–†–û–ô –ó–ê–ü–†–û–°
            print(f"–ó–ê–ü–†–û–° 2: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}...")

            # –î–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥—É—é –ª–æ–≥–∏–∫—É
            if current_page > 1:
                # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–æ—Ä–º—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                soup_temp = BeautifulSoup(response1.content, 'html.parser')

                # –ò—â–µ–º —Ñ–æ—Ä–º—É JJK020030Form (—Ñ–æ—Ä–º–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
                form_030 = soup_temp.find('form', attrs={'name': 'JJK020030Form'})

                if form_030:
                    print(f"–ù–∞–π–¥–µ–Ω–∞ —Ñ–æ—Ä–º–∞ JJK020030Form, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}")

                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è –∏–∑ —Ñ–æ—Ä–º—ã
                    pagination_form_data = {}
                    hidden_inputs = form_030.find_all('input', {'type': 'hidden'})

                    for hidden in hidden_inputs:
                        name = hidden.get('name')
                        value = hidden.get('value', '')
                        if name:
                            pagination_form_data[name] = value

                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
                    pagination_form_data.update({
                        'Transition': 'Transition',
                        'pageNo': str(current_page),
                        'currentPage': str(current_page)
                    })

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    url_results = "https://www2.jpx.co.jp/tseHpFront/JJK020030Action.do"
                    response2 = session.post(url_results, data=pagination_form_data)
                else:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
                    print(f"–§–æ—Ä–º–∞ JJK020030Form –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é")
                    response2 = session.post(url, data=form_data)
            else:
                # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å
                response2 = session.post(url, data=form_data)

            response2.raise_for_status()
            print(f"–ó–∞–ø—Ä–æ—Å 2 - –°—Ç–∞—Ç—É—Å: {response2.status_code}, –†–∞–∑–º–µ—Ä: {len(response2.content)} –±–∞–π—Ç")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            with open(f'jpx_page_{current_page}.html', 'w', encoding='utf-8') as f:
                f.write(response2.text)

            # –ü–∞—Ä—Å–∏–º –∫–æ–º–ø–∞–Ω–∏–∏ —Å —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            soup = BeautifulSoup(response2.content, 'html.parser')
            page_companies = parse_companies_from_soup(soup)

            print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page}: {len(page_companies)}")

            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫ –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
            for company in page_companies:
                company['page'] = current_page

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
            all_companies.extend(page_companies)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            update_statistics(page_companies, all_statistics)

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
            pagination_info = extract_pagination_info(soup)

            if pagination_info:
                total_items = pagination_info.get('total_items')
                total_pages = pagination_info.get('total_pages')
                has_next = pagination_info.get('has_next_page', False)

                print(f"\nüìñ –ü–∞–≥–∏–Ω–∞—Ü–∏—è:")
                print(f"  –¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {pagination_info.get('current_page')}")
                print(f"  –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
                print(f"  –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_items}")
                print(f"  –ï—Å—Ç—å —Å–ª–µ–¥—É—é—â–∞—è: {has_next}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                if not has_next or (total_pages and current_page >= total_pages):
                    print("üèÅ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞")
                    break

                if max_pages and current_page >= max_pages:
                    print(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç: {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
                    break

                if len(page_companies) == 0:
                    print("üõë –ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                    break

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                current_page += 1

                if delay > 0:
                    print(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ {delay} —Å–µ–∫...")
                    time.sleep(delay)

            else:
                print("üìñ –ü–∞–≥–∏–Ω–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                if len(page_companies) == 0:
                    print("üõë –ù–µ—Ç –∫–æ–º–ø–∞–Ω–∏–π –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏")
                    break
                else:
                    print("üìÑ –í–æ–∑–º–æ–∂–Ω–æ, –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞")
                    break

        # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüéâ –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {current_page}")
        print(f"üè¢ –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(all_companies)}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        show_final_statistics(all_statistics)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result = save_results(all_companies, all_statistics, current_page, total_items)

        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

        return {
            'success': False,
            'error': str(e),
            'partial_data': True,
            'companies_collected': len(all_companies),
            'companies': all_companies
        }


def parse_companies_from_soup(soup):
    """
    –ü–∞—Ä—Å–∏—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ soup (—Ç–æ—á–Ω–æ –∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ)
    """
    enhanced_data = []

    # –ò—â–µ–º –≤—Å–µ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
    hidden_inputs = soup.find_all('input', {'type': 'hidden'})
    company_records = {}

    for hidden in hidden_inputs:
        name = hidden.get('name', '')
        value = hidden.get('value', '')

        # –ü–∞—Ä—Å–∏–º –ø–æ–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ ccJjCrpSelKekkLst_st[N].field
        if 'ccJjCrpSelKekkLst_st[' in name and '].' in name:
            try:
                start = name.find('[') + 1
                end = name.find(']')
                index = int(name[start:end])

                field_start = name.find('.') + 1
                field_name = name[field_start:]

                if index not in company_records:
                    company_records[index] = {}

                company_records[index][field_name] = value
            except (ValueError, IndexError):
                continue

    # –ü–∞—Ä—Å–∏–º –≤–∏–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
    tables = soup.find_all('table')
    company_data = []

    for table in tables:
        rows = table.find_all('tr')
        for row in rows[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 4:  # –ú–∏–Ω–∏–º—É–º –∫–æ–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ, —Å–µ–≥–º–µ–Ω—Ç, –∏–Ω–¥—É—Å—Ç—Ä–∏—è
                code_cell = cells[0]
                code_text = code_cell.get_text(strip=True)

                if code_text.isdigit() and len(code_text) == 5:  # –ö–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏
                    company_info = {
                        'code': code_text,
                        'name': cells[1].get_text(strip=True) if len(cells) > 1 else '',
                        'market_segment': cells[2].get_text(strip=True) if len(cells) > 2 else '',
                        'industry': cells[3].get_text(strip=True) if len(cells) > 3 else '',
                        'fiscal_year_end': cells[4].get_text(strip=True) if len(cells) > 4 else '',
                        'alerts': cells[5].get_text(strip=True) if len(cells) > 5 else '',
                    }

                    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏
                    links = {}
                    for i, cell in enumerate(cells):
                        link = cell.find('a')
                        if link and link.get('href'):
                            if 'stock_detail' in link.get('href'):
                                links['stock_prices_url'] = link.get('href')
                            elif 'javascript:' not in link.get('href'):
                                links[f'link_{i}'] = link.get('href')

                    if links:
                        company_info['links'] = links

                    company_data.append(company_info)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–∫—Ä—ã—Ç—ã—Ö –ø–æ–ª–µ–π —Å –≤–∏–¥–∏–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    for company in company_data:
        code = company['code']
        enhanced_company = company.copy()

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–∫—Ä—ã—Ç—ã—Ö –ø–æ–ª–µ–π –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
        for record in company_records.values():
            if record.get('eqMgrCd') == code:
                enhanced_company['hidden_fields'] = record
                break

        enhanced_data.append(enhanced_company)

    # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è
    if not enhanced_data and company_records:
        for index, record in sorted(company_records.items()):
            if 'eqMgrCd' in record:  # –ï—Å—Ç—å –∫–æ–¥ –∫–æ–º–ø–∞–Ω–∏–∏
                company_info = {
                    'index': index,
                    'code': record.get('eqMgrCd', ''),
                    'name': record.get('eqMgrNm', ''),
                    'market_segment': record.get('szkbuNm', ''),
                    'industry': record.get('gyshDspNm', ''),
                    'fiscal_year_end': record.get('dspYuKssnKi', ''),
                    'hidden_fields': record
                }
                enhanced_data.append(company_info)

    return enhanced_data


def extract_pagination_info(soup):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏–∑ JPX
    """
    pagination_info = {
        'current_page': 1,
        'total_pages': 1,
        'total_items': 0,
        'items_per_page': 10,
        'has_next_page': False,
        'has_prev_page': False
    }

    # –ò—â–µ–º div —Å –∫–ª–∞—Å—Å–æ–º pagingmenu
    paging_menu = soup.find('div', class_='pagingmenu')

    if paging_menu:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ "Display of 1-10 items/1622"
        left_div = paging_menu.find('div', class_='left')
        if left_div:
            text = left_div.get_text()
            items_match = re.search(r'(\d+)-(\d+)\s+items?/(\d+)', text)
            if items_match:
                start_item = int(items_match.group(1))
                end_item = int(items_match.group(2))
                total_items = int(items_match.group(3))

                pagination_info['total_items'] = total_items
                pagination_info['items_per_page'] = end_item - start_item + 1
                pagination_info['current_page'] = (start_item - 1) // pagination_info['items_per_page'] + 1
                pagination_info['total_pages'] = (total_items + pagination_info['items_per_page'] - 1) // \
                                                 pagination_info['items_per_page']

        # –ò—â–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ –∫–ª–∞—Å—Å—É "current"
        current_element = paging_menu.find('b', class_='current')
        if current_element:
            try:
                pagination_info['current_page'] = int(current_element.get_text().strip())
            except ValueError:
                pass

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–Ω–æ–ø–∫–∏ "Next"
        next_div = paging_menu.find('div', class_='next_e')
        if next_div and next_div.find('a'):
            pagination_info['has_next_page'] = True

        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ 1, —Ç–æ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∞—è
        if pagination_info['current_page'] > 1:
            pagination_info['has_prev_page'] = True

    return pagination_info


def update_statistics(companies, all_statistics):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    for company in companies:
        segment = company.get('market_segment', 'Unknown')
        industry = company.get('industry', 'Unknown')

        all_statistics['segments'][segment] = all_statistics['segments'].get(segment, 0) + 1
        all_statistics['industries'][industry] = all_statistics['industries'].get(industry, 0) + 1


def show_final_statistics(all_statistics):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    if all_statistics['segments']:
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º:")
        for segment, count in sorted(all_statistics['segments'].items()):
            print(f"  {segment}: {count}")

    if all_statistics['industries']:
        print(f"\nüè≠ –¢–æ–ø-10 –∏–Ω–¥—É—Å—Ç—Ä–∏–π:")
        top_industries = sorted(all_statistics['industries'].items(), key=lambda x: x[1], reverse=True)[:10]
        for industry, count in top_industries:
            print(f"  {industry}: {count}")


def save_results(all_companies, all_statistics, pages_processed, total_items):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã
    """
    # –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    result = {
        'success': True,
        'method': 'jpx_pagination_scraping',
        'pages_processed': pages_processed,
        'total_companies': len(all_companies),
        'expected_total_items': total_items,
        'statistics': {
            'segments': all_statistics['segments'],
            'industries': dict(sorted(all_statistics['industries'].items(), key=lambda x: x[1], reverse=True))
        },
        'companies': all_companies
    }

    with open('jpx_all_companies.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: jpx_all_companies.json")

    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    simple_result = {
        'total_companies': len(all_companies),
        'expected_total': total_items,
        'pages_processed': pages_processed,
        'companies': [
            {
                'code': company.get('code'),
                'name': company.get('name'),
                'market_segment': company.get('market_segment'),
                'industry': company.get('industry'),
                'fiscal_year_end': company.get('fiscal_year_end'),
                'page': company.get('page'),
                'stock_prices_url': company.get('links', {}).get('stock_prices_url', '') if company.get('links') else ''
            }
            for company in all_companies
        ]
    }

    with open('jpx_all_companies_simple.json', 'w', encoding='utf-8') as f:
        json.dump(simple_result, f, ensure_ascii=False, indent=2)
    print(f"üíæ –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: jpx_all_companies_simple.json")

    return result


if __name__ == "__main__":
    print("üöÄ JPX SCRAPER (–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–±–æ—á–µ–≥–æ –∫–æ–¥–∞)")
    print("=" * 60)

    mode = input(
        "\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:\n1. –û–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (–±—ã—Å—Ç—Ä–æ)\n2. –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n3. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü\n–í–∞—à –≤—ã–±–æ—Ä (1-3): ").strip()

    if mode == "1":
        print("\nüìÑ –†–ï–ñ–ò–ú: –û–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞")
        result = jpx_two_step_request()

        if result.get('success'):
            print(f"\nüéâ –£–°–ü–ï–•! –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {result.get('companies_count', 0)}")
        else:
            print(f"\n‚ùå –û–®–ò–ë–ö–ê: {result.get('error')}")

    elif mode == "2":
        print("\nüìö –†–ï–ñ–ò–ú: –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
        delay = input("–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip()
        delay = float(delay) if delay.replace('.', '').isdigit() else 1.0

        print(f"‚ö†Ô∏è –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏!")
        confirm = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ").strip().lower()

        if confirm == 'y':
            result = jpx_with_pagination(max_pages=None, delay=delay)

            if result.get('success'):
                print(f"\nüéâ –£–°–ü–ï–•! –ö–æ–º–ø–∞–Ω–∏–π: {result.get('total_companies', 0)}")
            else:
                print(f"\n‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {result.get('companies_collected', 0)} –∫–æ–º–ø–∞–Ω–∏–π")

    elif mode == "3":
        print("\nüìë –†–ï–ñ–ò–ú: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ")

        max_pages = input("–ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–∞–Ω–∏—Ü: ").strip()
        max_pages = int(max_pages) if max_pages.isdigit() else 3

        delay = input("–ó–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip()
        delay = float(delay) if delay.replace('.', '').isdigit() else 1.0

        result = jpx_with_pagination(max_pages=max_pages, delay=delay)

        if result.get('success'):
            print(f"\nüéâ –£–°–ü–ï–•! –ö–æ–º–ø–∞–Ω–∏–π: {result.get('total_companies', 0)}")
        else:
            print(f"\n‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {result.get('companies_collected', 0)} –∫–æ–º–ø–∞–Ω–∏–π")

    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ!")